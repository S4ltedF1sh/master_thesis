{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b0ac882-b446-49d0-a87e-9db4fe826948",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, torch, logging\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments, pipeline\n",
    "from transformers import LongT5ForConditionalGeneration\n",
    "from peft import LoraConfig, PeftModel, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "from torch.utils.data import Dataset\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f079d4b-9f04-4dc0-b0c6-65db0ef4905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", use_fast=True, max_length=4000, truncate=True)\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c607e-ab32-4ead-ace7-262833c4f363",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f1a2ae9-6e2b-459b-8c71-8eeb57bd289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_prompt(txt, path, triggers):\n",
    "    inst = \"You're a doctor and you were given the following EMR by another doctor. You need to find some clinical triggers in this EMR that you think are important and need more infomation.\"\n",
    "    #trig_txt = \",\\n\".join(triggers)\n",
    "    with open(os.path.join(path, txt), \"r\", encoding=\"utf-8\") as f:\n",
    "        context = f.read()\n",
    "    prompt = \"<s>[INST] <<SYS>>\\n{inst}\\n<<SYS>>\\n\\nPlease find the clinical triggers for the following EMR.\\n\\nEMR: \\\"{auxiliary}\\\"\\n\\nClinical triggers found:\\n[/INST]\\n{trigs}\\n</s>\\n\"\n",
    "    return prompt.format(inst=inst, auxiliary=context, trigs=triggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c791dc2-6998-484d-ba58-f6ba95b37662",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"trigger_dataset_1k/dataset.json\") as f:\n",
    "    dataset = json.load(f)\n",
    "    \n",
    "new_data = {}\n",
    "for k, v in dataset.items():\n",
    "    triggers = [\"- \" + trig.strip(\" .\") for trig in v]\n",
    "    trig_txt = \"\\n\".join(triggers)\n",
    "    new_data[k] = trig_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6828ad86-acc1-47fc-86bc-d303be63a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = []\n",
    "path = \"trigger_dataset_1k/data\"\n",
    "for k, v in new_data.items():\n",
    "    txt = apply_prompt(k, path, v)\n",
    "    txts.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcba810c-87c4-4d54-b077-966eec45b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txts, eval_txts = train_test_split(txts, test_size=0.2)\n",
    "train_data = pd.DataFrame.from_dict({'text': train_txts})\n",
    "eval_data = pd.DataFrame.from_dict({'text': eval_txts})\n",
    "\n",
    "train_dataset = datasets.Dataset.from_pandas(train_data)\n",
    "eval_dataset = datasets.Dataset.from_pandas(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7e1aaf-84c9-43b1-a959-8416da2a430d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "You're a doctor and you were given the following EMR by another doctor. You need to find some clinical triggers in this EMR that you think are important and need more infomation.\n",
      "<<SYS>>\n",
      "\n",
      "Please find the clinical triggers for the following EMR.\n",
      "\n",
      "EMR: \"Admission Date :\n",
      "2019-06-25\n",
      "Discharge Date :\n",
      "2019-07-01\n",
      "Date of Birth :\n",
      "1950-04-19\n",
      "Sex :\n",
      "M\n",
      "Service :\n",
      "CARDIOTHORACIC\n",
      "Allergies :\n",
      "Penicillins / Norvasc / Verapamil\n",
      "Attending : Christopher Q Thompson , M.D.\n",
      "Chief Complaint :\n",
      "preop w/ for knee surgery revealed cardiac dz , asymptomatic\n",
      "Major Surgical or Invasive Procedure :\n",
      "CABGx4 ( 06-26 )\n",
      "History of Present Illness :\n",
      "69yoM with OA having workup for knee replacements found to be in Afib , had stress test that was positive followed by cardiac catheterization which revealed severe 3VD .\n",
      "Then referred for CABG\n",
      "Past Medical History :\n",
      "HTN\n",
      "chol\n",
      "AFib\n",
      "OA needs bilat arthroplasty\n",
      "CRI\n",
      "Social History :\n",
      "Lives with wife .\n",
      "Remote Timothy , quit 1990 . + ETOH ( 1-2 drinks / Rivero )\n",
      "Family History :\n",
      "Brother died 64 / MI\n",
      "Physical Exam :\n",
      "Admission\n",
      "VS T 98  HR 74  BP 136/88  RR 18\n",
      "Gen NAD\n",
      "Neuro A&Ox3 , nonfocal\n",
      "Chest CTA bilat\n",
      "CV irreg-irreg , no M/R\n",
      "Abdn soft , NT/ND/+BS\n",
      "Ext warm no edema\n",
      "Discharge\n",
      "T99.9  HR 70AF  BP 120/69  RR 20 O2sat 94%RA\n",
      "Neuro A&Ox3 MAE , non focal exam\n",
      "Pulm CTAB\n",
      "CV irreg irreg , sternum stable incision CDI\n",
      "Abdm soft , NT/ND/+BS\n",
      "Ext warm 2+ edema\n",
      "Pertinent Results :\n",
      "2019-06-25 04:10 PM\n",
      "GLUCOSE - 97 UREA N - 44 * CREAT - 2.0 * SODIUM - 143 POTASSIUM - 4.1 CHLORIDE - 107 TOTAL CO2 - 27 ANION GAP - 13\n",
      "2019-06-25 04:10 PM\n",
      "ALT(SGPT) - 19 AST(SGOT) - 19 LD(LDH) - 153 ALK PHOS - 58 TOT BILI - 0.4\n",
      "2019-06-25 04:10 PM\n",
      "ALBUMIN - 4.3\n",
      "2019-06-25 04:10 PM\n",
      "%HbA1c - 5.7\n",
      "2019-06-25 04:10 PM\n",
      "TSH - 1.2\n",
      "2019-06-25 04:10 PM\n",
      "WBC - 7.0 RBC - 3.92 * HGB - 12.6 * HCT - 36.4 * MCV - 93 MCH - 32.1 * MCHC - 34.6 RDW - 13.6\n",
      "2019-06-25 04:10 PM\n",
      "PLT COUNT - 207\n",
      "2019-06-25 04:10 PM\n",
      "PT - 11.8 PTT - 22.4 INR(PT) - 1.0\n",
      "2019-07-01 07:30 AM BLOOD WBC - 8.7 RBC - 3.18 * Hgb - 10.4 * Hct - 30.4 * MCV - 96 MCH - 32.7 * MCHC - 34.3 RDW - 13.5 Plt Ct - 303\n",
      "2019-07-01 07:30 AM BLOOD Plt Ct - 303\n",
      "2019-07-01 07:30 AM BLOOD PT - 14.4 * PTT - 24.2 INR(PT)- 1.3 *\n",
      "2019-06-30 06:45 AM BLOOD Glucose - 99 UreaN - 40 * Creat - 1.9 * Na - 137 K - 4.1 Cl - 99 HCO3 - 28 AnGap - 14\n",
      "CHEST ( PORTABLE A P)\n",
      "2019-06-30 11:26 AM\n",
      "CHEST ( PORTABLE AP )\n",
      "Reason : Effusion ? Pntx ?\n",
      "UNDERLYING MEDICAL CONDITION :\n",
      "69 year old man with s/p Off Pump CABG\n",
      "REASON FOR THIS EXAMINATION :\n",
      "Effusion ? Pntx ?\n",
      "PORTABLE CHEST ON 2019-06-30 AT 11:39\n",
      "INDICATION : CABG with chest tube in place .\n",
      "COMPARISON : 2019-06-29 .\n",
      "FINDINGS : Left chest tube remains in place with some density adjacent to the tip , but there is no significant interval change vs . prior .\n",
      "Specifically , there is no pneumothorax and no interval development of effusion .\n",
      "Cardiac silhouette and mediastinal contours are stable .\n",
      "IMPRESSION : No change vs . prior .\n",
      "DR. James A Roberts\n",
      "Brief Hospital Course :\n",
      "\"\n",
      "\n",
      "Clinical triggers found:\n",
      "[/INST]\n",
      "- HTN\n",
      "- quit 1990\n",
      "- OA\n",
      "- Off Pump\n",
      "- UREA N - 44 * CREAT - 2.0 *\n",
      "- Afib\n",
      "</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d983b28-cd2a-4e51-9136-be942c55af46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fbbd01a-58f0-474d-945d-b8bda886ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model.add_adapter(peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9baa1b26-2b34-4359-b55c-c63cfc5d9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"results/llama2/7b-trigger\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=10,\n",
    "    weight_decay=1e-6,\n",
    "    learning_rate=2e-4,\n",
    "    logging_dir=f\"results/logs\",\n",
    "    adam_epsilon=1e-3,\n",
    "    max_grad_norm=1.0,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    disable_tqdm=False,\n",
    "    gradient_accumulation_steps=16,\n",
    "    #bf16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad303b23-cb78-4756-9d78-fb502c0a59bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f7728a16244735bebdac944cdaaa76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/183 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8965a9741f4001a1b3ebfb6f5b1636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args_max_length = 1100\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args, \n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset, \n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length = args_max_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "344cc264-0f1e-412e-ab77-25086c2da41a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [55/55 29:00, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.352700</td>\n",
       "      <td>2.235887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.333700</td>\n",
       "      <td>2.215906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.120200</td>\n",
       "      <td>2.197095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.296600</td>\n",
       "      <td>2.184992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.021400</td>\n",
       "      <td>2.180815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ukp-storage-1/pham/miniconda3/envs/thesis/lib/python3.11/site-packages/transformers/integrations/peft.py:389: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/ukp-storage-1/pham/miniconda3/envs/thesis/lib/python3.11/site-packages/transformers/integrations/peft.py:389: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/ukp-storage-1/pham/miniconda3/envs/thesis/lib/python3.11/site-packages/transformers/integrations/peft.py:389: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/ukp-storage-1/pham/miniconda3/envs/thesis/lib/python3.11/site-packages/transformers/integrations/peft.py:389: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "/ukp-storage-1/pham/miniconda3/envs/thesis/lib/python3.11/site-packages/transformers/integrations/peft.py:389: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "835380ed-a4a5-4800-aca0-8a9ac97733a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/llama2/7b-trigger-5e/train_log.json\", \"w\") as f:\n",
    "    json.dump(train_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5695c3f-238a-4c88-9e59-fe3c5b8cd922",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d4afd41-4279-4ba2-8ae0-c47d33514652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf957bd534024841bb836d361242d33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"results/llama2/7b-trigger-5e/checkpoint-55\")\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "text_gen = pipeline(\n",
    "    task=\"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=4000,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2799473-e1c1-4352-bdae-ed08a7984ddb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trigger_dataset_3k7/data/record-30.txt',\n",
       " 'trigger_dataset_3k7/data/0109.txt',\n",
       " 'trigger_dataset_3k7/data/record-55.txt',\n",
       " 'trigger_dataset_3k7/data/record-28.txt',\n",
       " 'trigger_dataset_3k7/data/0245.txt',\n",
       " 'trigger_dataset_3k7/data/0313_p2.txt',\n",
       " 'trigger_dataset_3k7/data/0301.txt',\n",
       " 'trigger_dataset_3k7/data/0361.txt',\n",
       " 'trigger_dataset_3k7/data/0005.txt',\n",
       " 'trigger_dataset_3k7/data/0125.txt',\n",
       " 'trigger_dataset_3k7/data/0466.txt',\n",
       " 'trigger_dataset_3k7/data/record-176.txt',\n",
       " 'trigger_dataset_3k7/data/0045.txt',\n",
       " 'trigger_dataset_3k7/data/0149_p1.txt',\n",
       " 'trigger_dataset_3k7/data/0181.txt',\n",
       " 'trigger_dataset_3k7/data/0460.txt',\n",
       " 'trigger_dataset_3k7/data/0309.txt',\n",
       " 'trigger_dataset_3k7/data/record-140.txt',\n",
       " 'trigger_dataset_3k7/data/record-175.txt',\n",
       " 'trigger_dataset_3k7/data/0061_p2.txt',\n",
       " 'trigger_dataset_3k7/data/record-141_p1.txt',\n",
       " 'trigger_dataset_3k7/data/record-84.txt',\n",
       " 'trigger_dataset_3k7/data/0001.txt',\n",
       " 'trigger_dataset_3k7/data/0033.txt',\n",
       " 'trigger_dataset_3k7/data/record-105.txt',\n",
       " 'trigger_dataset_3k7/data/record-24.txt',\n",
       " 'trigger_dataset_3k7/data/0418.txt',\n",
       " 'trigger_dataset_3k7/data/0097.txt',\n",
       " 'trigger_dataset_3k7/data/0293.txt',\n",
       " 'trigger_dataset_3k7/data/record-74.txt',\n",
       " 'trigger_dataset_3k7/data/0237_p1.txt',\n",
       " 'trigger_dataset_3k7/data/record-32.txt',\n",
       " 'trigger_dataset_3k7/data/0412.txt',\n",
       " 'trigger_dataset_3k7/data/0161.txt',\n",
       " 'trigger_dataset_3k7/data/record-73.txt',\n",
       " 'trigger_dataset_3k7/data/record-144.txt',\n",
       " 'trigger_dataset_3k7/data/0273.txt',\n",
       " 'trigger_dataset_3k7/data/0289.txt',\n",
       " 'trigger_dataset_3k7/data/0009.txt',\n",
       " 'trigger_dataset_3k7/data/0436.txt',\n",
       " 'trigger_dataset_3k7/data/0053.txt',\n",
       " 'trigger_dataset_3k7/data/0149_p2.txt',\n",
       " 'trigger_dataset_3k7/data/0397.txt',\n",
       " 'trigger_dataset_3k7/data/0209.txt',\n",
       " 'trigger_dataset_3k7/data/record-52.txt',\n",
       " 'trigger_dataset_3k7/data/0285.txt',\n",
       " 'trigger_dataset_3k7/data/0253.txt',\n",
       " 'trigger_dataset_3k7/data/0389.txt',\n",
       " 'trigger_dataset_3k7/data/0037.txt',\n",
       " 'trigger_dataset_3k7/data/record-17.txt',\n",
       " 'trigger_dataset_3k7/data/0229.txt',\n",
       " 'trigger_dataset_3k7/data/record-38.txt',\n",
       " 'trigger_dataset_3k7/data/record-21.txt',\n",
       " 'trigger_dataset_3k7/data/0317.txt',\n",
       " 'trigger_dataset_3k7/data/record-122.txt',\n",
       " 'trigger_dataset_3k7/data/record-26.txt',\n",
       " 'trigger_dataset_3k7/data/0189.txt',\n",
       " 'trigger_dataset_3k7/data/record-82.txt',\n",
       " 'trigger_dataset_3k7/data/0281.txt',\n",
       " 'trigger_dataset_3k7/data/record-53.txt',\n",
       " 'trigger_dataset_3k7/data/0101.txt',\n",
       " 'trigger_dataset_3k7/data/0442.txt',\n",
       " 'trigger_dataset_3k7/data/record-19.txt',\n",
       " 'trigger_dataset_3k7/data/0337.txt',\n",
       " 'trigger_dataset_3k7/data/0129.txt',\n",
       " 'trigger_dataset_3k7/data/0421.txt',\n",
       " 'trigger_dataset_3k7/data/0345.txt',\n",
       " 'trigger_dataset_3k7/data/0193.txt',\n",
       " 'trigger_dataset_3k7/data/0349.txt',\n",
       " 'trigger_dataset_3k7/data/0113.txt',\n",
       " 'trigger_dataset_3k7/data/0081_p1.txt',\n",
       " 'trigger_dataset_3k7/data/record-123.txt',\n",
       " 'trigger_dataset_3k7/data/0093.txt',\n",
       " 'trigger_dataset_3k7/data/0365.txt',\n",
       " 'trigger_dataset_3k7/data/0041.txt',\n",
       " 'trigger_dataset_3k7/data/record-14.txt',\n",
       " 'trigger_dataset_3k7/data/record-27.txt',\n",
       " 'trigger_dataset_3k7/data/0233.txt',\n",
       " 'trigger_dataset_3k7/data/0445.txt',\n",
       " 'trigger_dataset_3k7/data/0401.txt',\n",
       " 'trigger_dataset_3k7/data/record-37_p1.txt',\n",
       " 'trigger_dataset_3k7/data/record-37_p2.txt',\n",
       " 'trigger_dataset_3k7/data/0121.txt',\n",
       " 'trigger_dataset_3k7/data/record-70.txt',\n",
       " 'trigger_dataset_3k7/data/record-124.txt',\n",
       " 'trigger_dataset_3k7/data/0221.txt',\n",
       " 'trigger_dataset_3k7/data/0057.txt',\n",
       " 'trigger_dataset_3k7/data/0313_p1.txt',\n",
       " 'trigger_dataset_3k7/data/0329.txt',\n",
       " 'trigger_dataset_3k7/data/0427.txt',\n",
       " 'trigger_dataset_3k7/data/0201.txt',\n",
       " 'trigger_dataset_3k7/data/record-177.txt',\n",
       " 'trigger_dataset_3k7/data/0241.txt',\n",
       " 'trigger_dataset_3k7/data/record-142.txt',\n",
       " 'trigger_dataset_3k7/data/0069.txt',\n",
       " 'trigger_dataset_3k7/data/record-141_p2.txt',\n",
       " 'trigger_dataset_3k7/data/0021.txt',\n",
       " 'trigger_dataset_3k7/data/record-16.txt',\n",
       " 'trigger_dataset_3k7/data/0081_p2.txt',\n",
       " 'trigger_dataset_3k7/data/0117.txt',\n",
       " 'trigger_dataset_3k7/data/record-13.txt',\n",
       " 'trigger_dataset_3k7/data/0061_p1.txt',\n",
       " 'trigger_dataset_3k7/data/0457.txt',\n",
       " 'trigger_dataset_3k7/data/0065.txt',\n",
       " 'trigger_dataset_3k7/data/0381.txt',\n",
       " 'trigger_dataset_3k7/data/0237_p2.txt',\n",
       " 'trigger_dataset_3k7/data/record-25.txt',\n",
       " 'trigger_dataset_3k7/data/record-51.txt',\n",
       " 'trigger_dataset_3k7/data/0393_p2.txt',\n",
       " 'trigger_dataset_3k7/data/0325.txt',\n",
       " 'trigger_dataset_3k7/data/0393_p1.txt',\n",
       " 'trigger_dataset_3k7/data/record-106.txt',\n",
       " 'trigger_dataset_3k7/data/0217.txt',\n",
       " 'trigger_dataset_3k7/data/record-68.txt',\n",
       " 'trigger_dataset_3k7/data/0225.txt',\n",
       " 'trigger_dataset_3k7/data/record-18.txt',\n",
       " 'trigger_dataset_3k7/data/record-29.txt',\n",
       " 'trigger_dataset_3k7/data/record-48.txt',\n",
       " 'trigger_dataset_3k7/data/0433.txt',\n",
       " 'trigger_dataset_3k7/data/record-108.txt',\n",
       " 'trigger_dataset_3k7/data/0177.txt',\n",
       " 'trigger_dataset_3k7/data/0165.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txts_list = os.listdir(\"trigger_dataset_3k7/data\")\n",
    "txts_list = [\"trigger_dataset_3k7/data/\" + txt for txt in txts_list if \"ipynb\" not in txt]\n",
    "txts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b92aa6-7efd-4c5f-b6c2-128084fd2350",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "You're a doctor and you were given the following EMR by another doctor. You need to find 5 clinical triggers in this EMR that you think are the most important and need more infomation.\n",
      "<<SYS>>\n",
      "\n",
      "Please find the clinical triggers for the following EMR.\n",
      "\n",
      "EMR: \"Admission Date :\n",
      "2015-09-16\n",
      "Discharge Date :\n",
      "2015-09-21\n",
      "Date of Birth :\n",
      "1962-09-26\n",
      "Sex :\n",
      "M\n",
      "Service :\n",
      "CARDIOTHOR\n",
      "REASON FOR ADMISSION :\n",
      "Mitral valve repair .\n",
      "HISTORY OF PRESENT ILLNESS :\n",
      "The patient is a 52 year old Czech speaking gentleman with a history of severe mitral regurgitation .\n",
      "For the past several years , the patient has continued to have significant exercise intolerance which has limited his ability to work .\n",
      "He reports severe dyspnea on exertion .\n",
      "The patient had a recent admission earlier in the month and he was discharged on 2015-09-10 , after undergoing cardiac catheterization .\n",
      "This was significant for demonstrating no flow-limited disease in the coronaries but several fistulae\n",
      "from the left anterior descending to the PA .\n",
      "Several of these were coil embolized during this admission .\n",
      "He tolerated this well , was sent home , and now returns for his mitral valve repair .\n",
      "PAST MEDICAL HISTORY :\n",
      "1. Mitral valve regurgitation .\n",
      "PAST SURGICAL HISTORY :\n",
      "None .\n",
      "MEDICATIONS ON ADMISSION :\n",
      "1. Atenolol 25 mg p.o. q. day .\n",
      "2. Enteric-coated aspirin 325 mg p.o. q. day .\n",
      "3. Nitroglycerin sublingual p.r.n.\n",
      "ALLERGIES :\n",
      "No known drug allergies .\n",
      "SOCIAL HISTORY :\n",
      "The patient is currently on Disability and lives at home with his wife .\n",
      "Kimberly was born in Great Britain .\n",
      "He denies any ETOH or tobacco use .\n",
      "FAMILY HISTORY :\n",
      "Negative .\n",
      "PHYSICAL EXAMINATION :\n",
      "The patient is in no acute distress .\n",
      "Temperature is 98.3 F. ; pulse is 76 ; blood pressure 113/52 ; breathing 18 ; 98% on room air .\n",
      "HEENT :\n",
      "The patient is missing many teeth .\n",
      "Oropharynx is clear .\n",
      "There is no cervical lymphadenopathy .\n",
      "Supple neck .\n",
      "Heart is regular rate and rhythm with a III/VI systolic ejection murmur .\n",
      "His lungs are clear to auscultation bilaterally .\n",
      "Abdomen is soft and nontender .\n",
      "The patient has no cyanosis , clubbing or edema in extremities .\n",
      "LABORATORY :\n",
      "On admission include a white blood cell count of 5.6 , hematocrit of 32.5 , platelets of 202 .\n",
      "Sodium of 140 , potassium of 3.5 , BUN of 4 , creatinine of 0.6 , glucose of 137 .\n",
      "Chest x-ray shows no infiltrate or pneumothorax .\n",
      "Cardiac catheterization demonstrates no significant disease in the coronary arteries .\n",
      "Two branches of an left anterior descending to PA fistula which was successfully coiled .\n",
      "There is a persistent flow through an inferior branch of the left anterior descending to PA fistula and a persistent branch of the circumflex to PA branch fistula which anatomically were not suitable for coil embolization .\n",
      "Ejection fraction was 60% .\n",
      "HOSPITAL COURSE :\n",
      "On the day of admission , the patient went to the Operating Room and underwent a minimally invasive\n",
      "mitral valve repair .\n",
      "He tolerated this procedure well .\n",
      "The patient was brought to the cardiothoracic Intensive Care Unit in stable condition on minimal pressor support .\n",
      "He was successfully weaned off this support .\n",
      "The patient was fully weaned from ventilatory support secondary to a persistent acidemia .\n",
      "This was treated with sodium bicarbonate and a Swan-Ganz was placed to provide close hemodynamic monitoring .\n",
      "The patient was found to have stable hemodynamics with appropriate mixed venous saturations in the 70% range .\n",
      "The patient was corrected to a normal pH of 7.41 by the first postoperative night and remained stable .\n",
      "He was then weaned off of ventilatory support and was successfully extubated .\n",
      "The patient did have a slight bit of confusion early in post-extubation course which cleared .\n",
      "This was also compounded by a language barrier since the patient cannot speak English .\n",
      "In addition , the patient 's early postoperative course had a tremendous urine output .\n",
      "It was equally up to 700 cc. an hour and a renal consultation was obtained .\n",
      "He underwent a head CT scan to rule out intracranial pathology leading to diabetes insipidus .\n",
      "This was negative .\n",
      "The patient 's serum and urine electrolytes indicated that this diuresis was appropriate .\n",
      "The patient 's urine output has decreased and his BUN and creatinine remained normal .\n",
      "The patient 's Foley was discontinued .\n",
      "He had developed some hematuria which has resolved .\n",
      "The patient has remained stable and is now ready for discharge to home with follow-up in approximately four weeks .\n",
      "DISCHARGE DIAGNOSES :\n",
      "1. Mitral regurgitation status post minimally invasive mitral valve repair .\n",
      "DISCHARGE MEDICATIONS :\n",
      "1. Lopressor 75 mg p.o. twice a day .\n",
      "2. Colace 100 mg p.o. twice a day .\n",
      "3. Percocet one to two p.o. q. four hours p.r.n.\n",
      "4. Aspirin 325 mg p.o. q. day .\n",
      "CONDITION ON DISCHARGE :\n",
      "Stable .\n",
      "DIGibsonE INSTRUCTIONS :\n",
      "1. The patient will follow-up with Dr. de las Grau in four weeks .\n",
      "2. He will follow-up with his primary care physician , Dr. Blake , in two weeks .\n",
      "3. The patient will call for any fevers or difficulties with the wound care , and will be instructed with an interpreter present .\n",
      "Bruce lou Murphy , M.D.\n",
      "07-760\n",
      "Dictated By : Ellen V Wise , M.D.\n",
      "MEDQUIST36\n",
      "D : 2015-09-21 08:34\n",
      "T : 2015-09-26 15:44\n",
      "JO B#:\n",
      "18430\n",
      "Signed electronically by : DR. Mary van den Mosley on : WED 2015-10-14 7:16 PM\n",
      "( End of Report )\"\n",
      "\n",
      "Clinical triggers found:\n",
      "[/INST]\n"
     ]
    }
   ],
   "source": [
    "inst = \"You're a doctor and you were given the following EMR by another doctor. You need to find 5 clinical triggers in this EMR that you think are the most important and need more infomation.\"\n",
    "#trig_txt = \",\\n\".join(triggers)\n",
    "template = \"<s>[INST] <<SYS>>\\n{inst}\\n<<SYS>>\\n\\nPlease find the clinical triggers for the following EMR.\\n\\nEMR: \\\"{auxiliary}\\\"\\n\\nClinical triggers found:\\n[/INST]\"\n",
    "\n",
    "prompts = []\n",
    "for txt in txts_list:\n",
    "    with open(txt, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    prompt = template.format(inst=inst, auxiliary=content)\n",
    "    prompts.append(prompt)\n",
    "print(prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ae5d71-0b46-40f2-8caf-f89249362d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"mimic-s2orc/pdf_list.txt\", \"r\") as f:\n",
    "    pdfs_list = f.readlines()\n",
    "dirs_list = [\"mimic-s2orc/\" + txt.strip().replace(\".pdf\", \"\") for txt in pdfs_list if \".pdf\" in txt]\n",
    "\n",
    "inst = \"You're a doctor and you were given the following EMR by another doctor. You need to find 5 clinical triggers in this EMR that you think are the most important and need more infomation.\"\n",
    "#trig_txt = \",\\n\".join(triggers)\n",
    "template = \"<s>[INST] <<SYS>>\\n{inst}\\n<<SYS>>\\n\\nPlease find the clinical triggers for the following EMR.\\n\\nEMR: \\\"{auxiliary}\\\"\\n\\nClinical triggers found:\\n[/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a3243f-c370-44ee-8b46-37db6f1a4933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mimic-s2orc/pdf/record-25/5849/26804946',\n",
       " 'mimic-s2orc/pdf/record-25/5849/31443997']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs_list[53:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7f4bc-2db7-4146-82bf-64838692dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_path in tqdm(dirs_list[53:55]):\n",
    "    out_dir = dir_path.replace(\"/pdf/\", \"/pdf_trigger/\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    txts = [txt for txt in os.listdir(dir_path) if \".txt\" in txt]\n",
    "    if len(txts) < 4:\n",
    "        n = len(txts)\n",
    "    elif len(txts) >= 4 and len(txts) < 7:\n",
    "        n = len(txts) - 2\n",
    "    elif len(txts) >= 7 and len(txts) < 10:\n",
    "        n = len(txts) - 3\n",
    "    else:\n",
    "        n = 7\n",
    "    for txt in txts[:n]:\n",
    "        with open(os.path.join(dir_path, txt), \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "        prompt = template.format(inst=inst, auxiliary=content)\n",
    "        out = text_gen(prompt)\n",
    "        out_path = os.path.join(out_dir, txt)\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(out[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
